{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c4d9fe",
   "metadata": {},
   "source": [
    "# Improved handling of potential evapotranspiration in hydrological studies with PyEt\n",
    "\n",
    "This notebook is supporting the manuscript: Vremec et al. \"Technical note: Improved handling of potential evapotranspiration in hydrological studies with *PyEt*\". Submitted to: Geoscientific Model Development.\n",
    "\n",
    "*M.Vremec (University of Graz), R. A. Collenteur (Eawag)*\n",
    "\n",
    "Data source: \n",
    "\n",
    "* Example 1: KNMI - https://www.knmi.nl/home\n",
    "* Example 2: E-OBS https://www.ecad.eu/\n",
    "* Example 3: ZAMG - https://data.hub.zamg.ac.at\n",
    "\n",
    "**The supporting Notebook is structured as follows:**\n",
    "\n",
    "* Benchmarking PET methods\n",
    "* Example 1: Estimation of PET from station data\n",
    "* Example 2: Estimate PET for gridded data\n",
    "* Example 3: Calibration of PET models\n",
    "* Example 4: The effect of $CO_2$ on future PET estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc987fb4-cbeb-4b10-9e26-79dd87f61f9f",
   "metadata": {},
   "source": [
    "Table 1: Corresponding literature to each method.\n",
    "\n",
    "| Method name       | Corresponding literature |\n",
    "| ----------------- | ------------------------ |\n",
    "| Penman            | Penman (1948) |\n",
    "| Penman-Monteith   | Monteith (1965) |\n",
    "| ASCE-PM           | Walter et al. (2000) |\n",
    "| FAO-56            | Allen et al. (1998) |\n",
    "| Priestley-Taylor  | Priestley and Taylor (1972), McMahon et al. (2013) |\n",
    "| Kimberly-Penman   | Wright (1982) |\n",
    "| Thom-Oliver       | Thom and Oliver (1977) |\n",
    "| Blaney-Criddle    | Xu et al. (2001), McMahon et al. (2013), Schrödter (1985) |\n",
    "| Hamon             | Hamon (1963), Ansorge et al. (2019), Oudin et al. (2005) |\n",
    "| Romanenko         | Romanenko (1961), Xu et al. (2001) |\n",
    "| Linacre           | Linacre (1977) |\n",
    "| Haude             | Haude (1955), Schiff (1975) |\n",
    "| Turc              | Turc (1961), Xu et al. (2001) |\n",
    "| Jensen-Haise      | Jensen and Haise (1963), Jensen et al. (2016), Oudin et al. (2005) |\n",
    "| McGuinness-Bordne | McGuinness and Bordne (1972) |\n",
    "| Hargreaves        | Hargreaves and Samani (1982) |\n",
    "| FAO-24            | Jensen et al. (1990) |\n",
    "| Abtew             | Abtew (1996) |\n",
    "| Makkink           | Makkink (1957), McMahon et al. (2013) |\n",
    "| Oudin             | Oudin et al. (2005) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c554ae6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75050118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Import needed Python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.stats import gaussian_kde\n",
    "import pylab\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import gc  # Import the garbage collection module\n",
    "\n",
    "import pyet\n",
    "import spotpy\n",
    "from utils import *\n",
    "pyet.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3398063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79810c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#edit default values for plots\n",
    "params = {\n",
    "    \"legend.fontsize\": \"15\",\n",
    "    \"axes.labelsize\": \"15\",\n",
    "    \"xtick.labelsize\": \"15\",\n",
    "    \"ytick.labelsize\": \"15\",\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"ytick.direction\": \"in\",}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0ebed8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Benchmarking PET methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read results from Guo et al., 2016\n",
    "df_guo = pd.read_excel(\"data/example_10/df_Guo_2016.xlsx\", index_col=\"daily\", \n",
    "                         parse_dates=True).iloc[:50, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variables\n",
    "lat = -0.6095\n",
    "elevation = 48\n",
    "\n",
    "rs = pyet.calc_rad_sol_in(df_guo[\"n\"], lat, as1=0.23, bs1=0.5, nn=None)  # Compute solar radiation [MJ/m2day]\n",
    "tmax = df_guo[\"Tmax\"]  # Daily maximum temperature [°C]\n",
    "tmin = df_guo[\"Tmin\"] # Daily minimum temperature [°C]\n",
    "tmean = (tmax+tmin)/2 # Daily mean temperature [°C]\n",
    "rhmax = df_guo[\"RHmax\"]  # Daily maximum relative humidity [%]\n",
    "rhmin = df_guo[\"RHmin\"]  # Daily minimum relative humidity [%]\n",
    "rh = (rhmax+rhmin)/2    # Daily mean relative humidity [%]\n",
    "uz = df_guo[\"uz\"]  # Wind speed at 10 m [m/s]\n",
    "z = 10  # Height of wind measurement [m]\n",
    "\n",
    "wind_penman = uz * np.log(2/0.001) / np.log(z/0.001) # wind speed at 2 m after Penman 1948\n",
    "wind_fao56 = uz * 4.87 / np.log(67.8*z-5.42)  # wind speed at 2 m after Allen et al., 1998\n",
    "\n",
    "lambda1 = pyet.calc_lambda(tmean=tmean)  # Latent Heat of Vaporization in PyEt [MJ kg-1] \n",
    "lambda0 = 2.45  # Latent Heat of Vaporization in Guo et al., 2016 [MJ kg-1] \n",
    "lambda_corr = lambda1 / lambda0  # Correction factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking against R-Evapotranspiration package\n",
    "df_pyet_guo = pyet.calculate_all(tmean, wind_fao56, rs, elevation, lat, tmax, tmin, rh, \n",
    "                                   rhmax=rhmax, rhmin=rhmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b076e",
   "metadata": {},
   "source": [
    "### Test Penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf863e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "pyet_penman = pyet.penman(tmean, wind_penman, rs=rs, elevation=elevation, lat=lat, tmax=tmax, \n",
    "                          tmin=tmin, rh=rh, rhmax=rhmax, rhmin=rhmin, aw=2.626, bw=1.381, albedo=0.08) * lambda_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ce8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(pyet_penman.iloc[:10].round(1).values, df_guo[\"Penman\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e434b",
   "metadata": {},
   "source": [
    "### Test FAO-56, ASCE, Penman-Monteith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62525eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(df_pyet_guo[\"FAO-56\"].iloc[:10].round(1).values, df_guo[\"PM\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyet_pmasce = pyet.pm_asce(tmean, wind_fao56, rs=rs, elevation=elevation, lat=lat, tmax=tmax, \n",
    "                           tmin=tmin, rh=rh, rhmax=rhmax, rhmin=rhmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b598a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(pyet_pmasce.iloc[:10].round(1).values, df_guo[\"PM\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e798b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyet_pm = pyet.pm(tmean, wind_fao56, rs=rs, elevation=elevation, lat=lat, tmax=tmax, tmin=tmin, rh=rh, \n",
    "                  rhmax=rhmax, rhmin=rhmin) * lambda_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a984d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(pyet_pm.iloc[:10].round(1).values, df_guo[\"PM\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d92a3b",
   "metadata": {},
   "source": [
    "### Test Makkink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b645390",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyet_makk = (pyet.makkink(tmean, rs=rs, elevation=elevation, k=0.61)  * lambda_corr - 0.12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(pyet_makk.iloc[:10].round(1).values, df_guo[\"Makkink\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df438315",
   "metadata": {},
   "source": [
    "### Test Priestley-Taylor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90229e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal((df_pyet_guo[\"Priestley-Taylor\"]*lambda_corr).iloc[:10].round(1).values, df_guo[\"PT\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a073713e",
   "metadata": {},
   "source": [
    "### Hargreaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyet_hargreaves = pyet.hargreaves(tmean, tmax, tmin, lat, method=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(pyet_hargreaves.iloc[:10].round(1).values, df_guo[\"Har\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8f37b",
   "metadata": {},
   "source": [
    "### Test Hamon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyet_hamon = pyet.hamon(tmean, lat=lat, n=df_guo[\"n\"], tmax=tmax, tmin=tmin, method=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f49a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(pyet_hamon.iloc[:10].round(1).values, df_guo[\"Hamon\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e2662",
   "metadata": {},
   "source": [
    "### Blaney Criddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e469cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyet_bc = pyet.blaney_criddle(tmean, lat, rhmin=rhmin, wind=wind_fao56, method=2, n=df_guo[\"n\"], clip_zero=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(pyet_bc.iloc[:10].round(1).values, df_guo[\"BC\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf4c577",
   "metadata": {},
   "source": [
    "### Romanenko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(df_pyet_guo[\"Romanenko\"].iloc[:10].round(1).values, df_guo[\"Romanenko\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b841b",
   "metadata": {},
   "source": [
    "### McGuinness-Bordne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb04f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal((df_pyet_guo[\"Mcguinness-Bordne\"]*lambda_corr).iloc[:10].round(1).values, \n",
    "               df_guo[\"McG\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f298f524",
   "metadata": {},
   "source": [
    "### Jensen-Haise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ccfd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal((df_pyet_guo[\"Jensen-Haise\"]*lambda_corr).iloc[:10].round(1).values, \n",
    "               df_guo[\"JH\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9a13a1",
   "metadata": {},
   "source": [
    "### Linacre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f18b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyet_linacre = pyet.linacre(tmean, elevation, lat, tdew=df_guo[\"Tdew\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94104178",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(pyet_linacre.iloc[:10].round(1).values, \n",
    "               df_guo[\"Linacre\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe4a0c",
   "metadata": {},
   "source": [
    "### Abtew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97f2184",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyet_abtew = pyet.abtew(tmean, rs, k=0.52) * lambda_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(pyet_abtew.iloc[:10].round(1).values, \n",
    "               df_guo[\"Abtew\"].iloc[:10].round(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6a0fc9",
   "metadata": {},
   "source": [
    "### Turc\n",
    "**Note** df_guo[\"Turc\"] was modified because a bug was found in R-Evapotranspiration for values when RH < 50. This was found after comparing with McMahon et al. 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460dddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(df_pyet_guo[\"Turc\"].values.round(1),\n",
    "               df_guo[\"Turc\"].values.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cc537f",
   "metadata": {},
   "source": [
    "### Benchmarking against McMahon et al. 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5fb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking against McMahon et al. 2016\n",
    "# Makkink # Based on example S19.91, p 80 McMahon_etal_2013\n",
    "tmean = pd.Series([11.5], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "rs = pd.Series([17.194], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "elevation = 546\n",
    "mcm_mak = [2.3928, (pyet.makkink(tmean, rs, elevation=elevation, k=0.61)) -0.12] # correction for different formula in McMahon_2013\n",
    "# Blaney Criddle # Based on example S19.93, McMahon_etal_2013\n",
    "tmean = pd.Series([11.5], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "rhmin = pd.Series([25], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "wind = pd.Series([0.5903], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "n = pd.Series([10.7], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "py = pd.Series([0.2436], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "lat = -23.7951 * np.pi / 180\n",
    "mcm_bc = [3.1426, pyet.blaney_criddle(tmean, lat, wind=wind, n=n, rhmin=rhmin, py=py, method=2)]\n",
    "# Based on example S19.99, McMahon_etal_2013 # Based on example S19.99, McMahon_etal_2013\n",
    "tmean = pd.Series([11.5], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "rhmean = pd.Series([48], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "rs = pd.Series([17.194], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "mcm_turc = [pyet.turc(tmean, rs, rhmean, k=0.32), 2.6727]\n",
    "# Based on example S19.101, McMahon_etal_2013\n",
    "tmean = pd.Series([11.5], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "tmax = pd.Series([21], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "tmin = pd.Series([2], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "lat = -23.7951 * np.pi / 180\n",
    "mcm_har = [4.1129, pyet.hargreaves(tmean, tmax, tmin, lat, method=1)]\n",
    "\n",
    "# Based on example S19.109, McMahon_etal_2013\n",
    "tmean = pd.Series([11.5], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "rn = pd.Series([8.6401], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "elevation = 546\n",
    "mcm_pt = [2.6083, pyet.priestley_taylor(tmean, rn=rn, elevation=elevation, alpha=1.26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc107162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on example 5.1, P89 Schrodter 1985\n",
    "tmean = pd.Series([17.3], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "lat = 50 * np.pi / 180\n",
    "sch_bc = [3.9, pyet.blaney_criddle(tmean, lat, method=0)]\n",
    "# Based on example 5.2, P95 Schrodter 1985\n",
    "tmean = pd.Series([21.5], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "ea = pd.Series([1.19], index=pd.DatetimeIndex([\"1980-07-20\"]))\n",
    "e0 = pyet.calc_e0(tmean)\n",
    "rh = ea / e0 * 100\n",
    "sch_haude = [3.6, pyet.haude(tmean, rh=rh, k=0.26 / 0.35)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761295d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmarking against FAO-56\n",
    "# Hargreasves # Based on example S19.46,p 78 TestFAO56\n",
    "tmax = pd.Series([26.6], index=pd.DatetimeIndex([\"2015-07-15\"]))\n",
    "tmin = pd.Series([14.8], index=pd.DatetimeIndex([\"2015-07-15\"]))\n",
    "tmean = (tmax + tmin) / 2\n",
    "lat = 45.72 * np.pi / 180\n",
    "fao_har = [5.0, pyet.hargreaves(tmean, tmax, tmin, lat)]\n",
    "\n",
    "# Based on Example 18, p. 72 FAO.\n",
    "wind = pd.Series([2.078], index=pd.DatetimeIndex([\"2015-07-06\"]))\n",
    "tmax = pd.Series([21.5], index=pd.DatetimeIndex([\"2015-07-06\"]))\n",
    "tmin = pd.Series([12.3], index=pd.DatetimeIndex([\"2015-07-06\"]))\n",
    "tmean = (tmax + tmin) / 2\n",
    "rhmax = pd.Series([84], index=pd.DatetimeIndex([\"2015-07-06\"]))\n",
    "rhmin = pd.Series([63], index=pd.DatetimeIndex([\"2015-07-06\"]))\n",
    "rs = pd.Series([22.07], index=pd.DatetimeIndex([\"2015-07-06\"]))\n",
    "n = 9.25\n",
    "nn = 16.1\n",
    "elevation = 100\n",
    "lat = 50.80 * np.pi / 180\n",
    "fao_56 = [3.9, pyet.pm_fao56(tmean, wind, elevation=elevation, lat=lat, rs=rs, tmax=tmax, tmin=tmin, rhmax=rhmax,\n",
    "                            rhmin=rhmin, n=n, nn=nn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1251c4-7423-4b98-a7ed-d0d359a99eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metrics(ax, x, y):\n",
    "    ax.text(0.55, 0.04, \"$Bias$ = \" + str(\n",
    "        round(bias(np.asarray(y), np.asarray(x)), 2)) +\n",
    "            \"\\n\" + \"$R^2$ = \" + str(\n",
    "        round(rsquared(np.asarray(y), np.asarray(x)),\n",
    "              2)) +\n",
    "            \"\\n\" + \"KGE = \" + str(\n",
    "        round(kge(np.asarray(y), np.asarray(x)), 2)), fontsize=12,\n",
    "            color=\"k\", zorder=10, transform=ax.transAxes)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09eb52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "figw_1c = 8.5  # maximum width for 1 column\n",
    "figw_2c = 17.5  # maximum width for 2 columns\n",
    "cm1 = 1 / 2.54  # centimeters in inches\n",
    "fs = 15\n",
    "ms1 = 20\n",
    "ms2 = 60\n",
    "\n",
    "fig,axs=plt.subplots(ncols=7, nrows=2, figsize=(figw_2c,5))\n",
    "axs[0,0].scatter(df_guo[\"Penman\"], pyet_penman, c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[0,0].text(0.04, 0.9, \"Penman\", transform=axs[0, 0].transAxes, fontsize=fs)\n",
    "add_metrics(axs[0,0], df_guo[\"Penman\"], pyet_penman)\n",
    "\n",
    "axs[0,1].scatter(df_guo[\"PM\"], df_pyet_guo[\"FAO-56\"], c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[0,1].text(0.04, 0.8, \"FAO-56\", transform=axs[0, 1].transAxes, fontsize=fs)\n",
    "axs[0,1].scatter(fao_56[0], fao_56[1], c=\"goldenrod\", marker=\"^\", s=ms2, zorder=10)\n",
    "\n",
    "axs[0,1].scatter(df_guo[\"PM\"], pyet_pmasce, c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[0,1].text(0.04, 0.7, \"ASCE-PM\", transform=axs[0, 1].transAxes, fontsize=fs)\n",
    "add_metrics(axs[0,1], np.append(df_guo[\"PM\"].values, fao_56[0]), \n",
    "            np.append(df_pyet_guo[\"FAO-56\"].values, fao_56[1]))\n",
    "\n",
    "axs[0,1].scatter(df_guo[\"PM\"], pyet_pm, c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[0,1].text(0.04, 0.9, \"Penman-Monteith\", transform=axs[0, 1].transAxes, fontsize=fs)\n",
    "\n",
    "axs[0,2].scatter(df_guo[\"Makkink\"], pyet_makk, c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[0,2].text(0.04, 0.9, \"Makkink\", transform=axs[0, 2].transAxes, fontsize=fs)\n",
    "axs[0,2].scatter(mcm_mak[0], mcm_mak[1], c=\"red\", marker=\"x\", s=ms2, zorder=10)\n",
    "add_metrics(axs[0,2], np.append(df_guo[\"Makkink\"].values, mcm_mak[0]), \n",
    "            np.append(pyet_makk.values, mcm_mak[1]))\n",
    "\n",
    "\n",
    "axs[0,3].scatter(df_guo[\"PT\"], df_pyet_guo[\"Priestley-Taylor\"], c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[0,3].text(0.04, 0.9, \"Priestley-Taylor\", transform=axs[0, 3].transAxes, fontsize=fs)\n",
    "axs[0,3].scatter(mcm_pt[0], mcm_pt[1], c=\"red\", marker=\"x\", s=ms2, zorder=10)\n",
    "add_metrics(axs[0,3], np.append(df_guo[\"PT\"].values, mcm_pt[0]), \n",
    "            np.append(df_pyet_guo[\"Priestley-Taylor\"].values, mcm_pt[1]))\n",
    "\n",
    "p1=axs[0,4].scatter(df_guo[\"Har\"], pyet_hargreaves, c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[0,4].text(0.04, 0.9, \"Hargreaves\", transform=axs[0, 4].transAxes, fontsize=fs)\n",
    "p2=axs[0,4].scatter(fao_har[0], fao_har[1], c=\"goldenrod\", marker=\"^\", s=ms2, zorder=10)\n",
    "p3=axs[0,4].scatter(mcm_har[0], mcm_har[1], c=\"red\", marker=\"x\", s=ms2, zorder=10)\n",
    "add_metrics(axs[0,4], np.append(df_guo[\"Har\"].values, mcm_har[0]), \n",
    "            np.append(pyet_hargreaves.values, mcm_har[1]))\n",
    "\n",
    "axs[0,5].scatter(df_guo[\"Hamon\"], pyet_hamon, c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[0,5].text(0.04, 0.9, \"Hamon\", transform=axs[0, 5].transAxes, fontsize=fs)\n",
    "add_metrics(axs[0,5], df_guo[\"Hamon\"], pyet_hamon)\n",
    "\n",
    "axs[0, 6].scatter(df_guo[\"BC\"], pyet_bc, c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[0,6].text(0.04, 0.9, \"Blaney-Criddle\", transform=axs[0, 6].transAxes, fontsize=fs)\n",
    "axs[0,6].scatter(mcm_bc[0], mcm_bc[1], c=\"red\", marker=\"x\", s=ms2, zorder=10)\n",
    "p4=axs[0,6].scatter(sch_bc[0], sch_bc[1], c=\"darkviolet\", marker=\"d\", s=ms2, zorder=10)\n",
    "add_metrics(axs[0,6], np.append(df_guo[\"BC\"].values, sch_bc[0]), \n",
    "            np.append(pyet_bc.values, sch_bc[1]))\n",
    "\n",
    "axs[1,0].scatter(df_guo[\"Romanenko\"], df_pyet_guo[\"Romanenko\"], c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[1,0].text(0.04, 0.9, \"Romanenko\", transform=axs[1, 0].transAxes, fontsize=fs)\n",
    "add_metrics(axs[1,0], df_guo[\"Romanenko\"], df_pyet_guo[\"Romanenko\"])\n",
    "\n",
    "axs[1,1].scatter(df_guo[\"McG\"], df_pyet_guo[\"Mcguinness-Bordne\"], c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[1,1].text(0.04, 0.9, \"Mcguinness-Bordne\", transform=axs[1, 1].transAxes, fontsize=fs)\n",
    "add_metrics(axs[1,1], df_guo[\"McG\"], df_pyet_guo[\"Mcguinness-Bordne\"])\n",
    "\n",
    "axs[1,2].scatter(df_guo[\"JH\"], df_pyet_guo[\"Jensen-Haise\"], c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[1,2].text(0.04, 0.9, \"Jensen-Haise\", transform=axs[1, 2].transAxes, fontsize=fs)\n",
    "add_metrics(axs[1,2], df_guo[\"JH\"], df_pyet_guo[\"Jensen-Haise\"])\n",
    "\n",
    "axs[1,3].scatter(df_guo[\"Linacre\"], pyet_linacre, c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[1,3].text(0.04, 0.9, \"Linacre\", transform=axs[1, 3].transAxes, fontsize=fs)\n",
    "add_metrics(axs[1,3], df_guo[\"Linacre\"], pyet_linacre)\n",
    "\n",
    "axs[1,4].scatter(df_guo[\"Abtew\"], df_pyet_guo[\"Abtew\"], c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[1,4].text(0.04, 0.9, \"Abtew\", transform=axs[1, 4].transAxes, fontsize=fs)\n",
    "add_metrics(axs[1,4], df_guo[\"Abtew\"], df_pyet_guo[\"Abtew\"])\n",
    "\n",
    "axs[1,5].scatter(df_guo[\"Turc\"], df_pyet_guo[\"Turc\"], c=\"None\", marker=\"o\", s=20, edgecolors=\"k\")\n",
    "axs[1,5].text(0.04, 0.9, \"Turc\", transform=axs[1, 5].transAxes, fontsize=fs)\n",
    "axs[1,5].scatter(mcm_turc[0], mcm_turc[1], c=\"red\", marker=\"x\", s=ms2, zorder=10)\n",
    "add_metrics(axs[1,5], np.append(df_guo[\"Turc\"].values, mcm_turc[0]), \n",
    "            np.append(df_pyet_guo[\"Turc\"].values, mcm_turc[1]))\n",
    "\n",
    "axs[1,6].text(0.04, 0.9, \"Haude\", transform=axs[1, 6].transAxes, fontsize=fs)\n",
    "axs[1,6].scatter(sch_haude[0], sch_haude[1], c=\"darkviolet\", marker=\"d\", s=ms2, zorder=10)\n",
    "\n",
    "for i in (0,1,2,3,4,5,6):\n",
    "    axs[0,i].set_xticklabels([]) \n",
    "    for j in (0, 1):\n",
    "        axs[j,i].set_xlim(0,10)\n",
    "        axs[j,i].set_ylim(0,10)\n",
    "        axs[j,i].plot([0, 10], [0, 10], color=\"gray\", zorder=-10)\n",
    "        axs[j,i].set_xticks([0, 5])\n",
    "        axs[j,i].set_yticks([0, 5])\n",
    "        axs[j,i].set_yticklabels([])\n",
    "        axs[j,0].set_yticklabels([0, 5])\n",
    "\n",
    "axs[0,i].set_yticklabels([]) \n",
    "\n",
    "axs[0,0].legend((p1,p2,p3,p4), (\"R-Evapotranspiration package, Guo et al., 2016\", \n",
    "                                \"Allen et al., 1998\", \"McMahon et al., 2013\", \"Schrodter, 1985\"), ncol=4, loc=[0,1.02], fontsize=16)\n",
    "fig.supxlabel(\"PET$_{benchmark}$ [mm/day]\", x=0.475, fontsize=16)\n",
    "fig.supylabel(\"PET$_{pyet}$ [mm/day]\", fontsize=16)\n",
    "fig.subplots_adjust(wspace=0.05, hspace=0.05, left=0.05)\n",
    "plt.tight_layout();\n",
    "#fig.savefig(\"figure1.png\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a45751",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Example 1: Estimation of PET from station data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c4c06",
   "metadata": {},
   "source": [
    "In this example potential evapotranspiration is estimated for the town of De Bilt in The Netherlands using data provided by the Royal Netherlands Meteorological Institute (KNMI). The reference method used by the KNMI for the estimation of potential evapotranspiration is the Makkink method, also implemented in *PyEt*. The $PET$ computed with the Makkink method is compared to the $PET$ values from all other methods in *PyEt*. A number of steps are taken in a Python script to estimate $PET$. The code implementing these steps is shown in the code example bellow. *PyEt* provides a convenience method to compute the $PET$ with all available methods, *pyet.calculate_all()*.\n",
    "\n",
    "Data source: KNMI - https://dataplatform.knmi.nl/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfecbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the meteorological data.\n",
    "meteo = pd.read_csv(\"data//example_10//10_example_meteo.csv\", index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab21af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the necessary input data for the $PET$ model.\n",
    "tmean, tmax, tmin, rh, rs, wind, pet_knmi = (meteo[col] for col in meteo.columns)\n",
    "lat = 0.91  # define latitude [radians]\n",
    "elevation = 4  # define elevation [meters above sea-level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the potential evapotranspiration with all methods or the method of choice.\n",
    "pet_df  = pyet.calculate_all(tmean, wind, rs, elevation, lat, tmax, tmin, rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4973b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize and analyze the results.\n",
    "viridis = cm.get_cmap('viridis', len(pet_df.columns))\n",
    "colors = [viridis(i) for i in range(0, len(pet_df.columns))]\n",
    "colors[-2] = \"k\"\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(6,5), layout=\"constrained\")\n",
    "axs = axs.flatten()\n",
    "axs[3].axis(\"off\")\n",
    "\n",
    "pet_df.plot(color=colors, legend=False, ax=axs[0], alpha=0.8, drawstyle=\"steps-mid\")\n",
    "axs[0].xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "axs[0].set_ylabel(\"PET [mm/day]\")\n",
    "axs[0].set_xlabel(\"\")\n",
    "axs[0].set_xticklabels([])\n",
    "\n",
    "handles = pet_df.cumsum().plot(color=colors, legend=False, ax=axs[2], alpha=0.8)\n",
    "axs[2].set_ylabel(\"Cum. PET [mm]\")\n",
    "axs[2].xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "axs[2].set_xlabel(\"\")\n",
    "\n",
    "sns.boxplot(data=pet_df, ax=axs[1], palette=colors)\n",
    "axs[1].set_ylabel(\"PET [mm/day]\")\n",
    "axs[1].set_xlabel(\"\")\n",
    "\n",
    "axs[1].set_xticklabels([])\n",
    "\n",
    "for i, letter in enumerate([\"a\", \"b\", \"c\"]):\n",
    "    axs[i].text(0.05, 0.9, \"({})\".format(letter), transform=axs[i].transAxes, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "axs[2].legend(loc=(1.05,0.1), ncol=2, bbox_transform=axs[0].transAxes, fontsize=8);\n",
    "#fig.savefig(\"figure2.png\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f5fd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 4. Example 2: Estimate PET for gridded data\n",
    "\n",
    "Data source: E-OBS https://www.ecad.eu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31888e0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load E-OBS data\n",
    "wind = xr.open_dataset(\"data/example_10/fg_ens_mean_0.25deg_reg_2018_v25.0e.nc\", \n",
    "                       engine=\"netcdf4\")[\"fg\"]\n",
    "tmax = xr.open_dataset(\"data/example_10/tx_ens_mean_0.25deg_reg_2018_v25.0e.nc\", \n",
    "                       engine=\"netcdf4\").sel(longitude=slice(wind.longitude.min(), wind.longitude.max()), \n",
    "                                             latitude=slice(wind.latitude.min(), wind.latitude.max()))[\"tx\"]\n",
    "tmin = xr.open_dataset(\"data/example_10/tn_ens_mean_0.25deg_reg_2018_v25.0e.nc\", \n",
    "                       engine=\"netcdf4\").sel(longitude=slice(wind.longitude.min(), wind.longitude.max()), \n",
    "                                             latitude=slice(wind.latitude.min(), wind.latitude.max()))[\"tn\"]\n",
    "tmean = xr.open_dataset(\"data/example_10/tg_ens_mean_0.25deg_reg_2018_v25.0e.nc\", \n",
    "                        engine=\"netcdf4\").sel(longitude=slice(wind.longitude.min(), wind.longitude.max()), \n",
    "                                              latitude=slice(wind.latitude.min(), wind.latitude.max()))[\"tg\"]\n",
    "rs = xr.open_dataset(\"data/example_10/qq_ens_mean_0.25deg_reg_2018_v25.0e.nc\", \n",
    "                     engine=\"netcdf4\").sel(lon=slice(wind.longitude.min(), wind.longitude.max()), \n",
    "                                           lat=slice(wind.latitude.min(), wind.latitude.max()))\n",
    "rs = rs.rename_dims({\"lon\":\"longitude\", \n",
    "                     \"lat\":\"latitude\"}).rename({\"lon\":\"longitude\", \n",
    "                                                \"lat\":\"latitude\"}).sel(ensemble=10)[\"qq\"] * 86400 / 1000000  # concert to [MJ/m2day]\n",
    "rh = xr.open_dataset(\"data/example_10/hu_ens_mean_0.25deg_reg_2018_v25.0e.nc\", \n",
    "                     engine=\"netcdf4\").sel(lon=slice(wind.longitude.min(), wind.longitude.max()), \n",
    "                                           lat=slice(wind.latitude.min(), wind.latitude.max()))\n",
    "rh = rh.rename_dims({\"lon\":\"longitude\", \"lat\":\"latitude\"}).rename({\"lon\":\"longitude\", \"lat\":\"latitude\"})[\"hu\"]\n",
    "wind = wind.sel(longitude=slice(rh.longitude.min(), rh.longitude.max()), latitude=slice(rh.latitude.min(), rh.latitude.max()))\n",
    "elevation =  xr.open_dataset(\"data/example_10/elev_ens_0.25deg_reg_v25.0e.nc\", \n",
    "                     engine=\"netcdf4\").sel(longitude=slice(wind.longitude.min(), wind.longitude.max()), \n",
    "                                           latitude=slice(wind.latitude.min(), wind.latitude.max()))[\"elevation\"].fillna(0)\n",
    "lat = tmean.latitude * np.pi / 180\n",
    "lat = lat.expand_dims(dim={\"longitude\":tmean.longitude}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b4c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate potential Evapotranspiration\n",
    "pm_fao56 = pyet.pm_fao56(tmean, wind, rs=rs, elevation=elevation, lat=lat, tmax=tmax, tmin=tmin, rh=rh)\n",
    "makkink = pyet.makkink(tmean, rs, elevation=elevation)\n",
    "hargreaves = pyet.hargreaves(tmean, tmax, tmin, lat=lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2d1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmax, vmin = 7, 0\n",
    "cmap = \"YlOrRd\"\n",
    "\n",
    "try:\n",
    "    import cartopy.crs as ccrs   \n",
    "    import cartopy.feature as cf\n",
    "    fs = 15  # fontsize\n",
    "    fig, axs = plt.subplots(ncols=3, nrows=3, figsize=(16, 9), sharey=True, sharex=True, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    for date, i in zip([\"2018-6-6\", \"2018-6-7\", \"2018-6-8\"],[0,1,2]):\n",
    "        pm_fao56.sel(time=date).plot(ax=axs[0,i],vmax=vmax, vmin=vmin, add_colorbar=False, cmap=cmap)\n",
    "        makkink.sel(time=date).plot(ax=axs[1,i],vmax=vmax, vmin=vmin, add_colorbar=False, cmap=cmap)\n",
    "        im = hargreaves.sel(time=date).plot(ax=axs[2,i],vmax=vmax, vmin=vmin, add_colorbar=False, cmap=cmap) \n",
    "        lon_min, lon_max, lat_min, lat_max = (-14, 42, 35, 67)\n",
    "        for j in (0,1,2):\n",
    "            axs[j, i].add_feature(cf.BORDERS.with_scale(\"50m\"), lw=0.3)\n",
    "            axs[j, i].add_feature(cf.COASTLINE.with_scale(\"50m\"), lw=0.4)\n",
    "            axs[j, i].set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "    for date, i in zip([\"2018-6-6\", \"2018-6-7\", \"2018-6-8\"],[0,1,2]):\n",
    "        for j in (0,1,2):      \n",
    "            axs[j,i].set_title(\"\") \n",
    "            gl = axs[i,j].gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False, linewidth=0.25)\n",
    "            gl.right_labels = False\n",
    "            gl.top_labels = False\n",
    "            gl.xlabel_style = {'size': 12}\n",
    "            gl.ylabel_style = {'size': 12}\n",
    "            if i == 0 or i == 1:\n",
    "                gl.bottom_labels = False\n",
    "            if j == 1 or j == 2:\n",
    "                gl.left_labels = False \n",
    "        axs[0,i].set_title(\"date=\"+date, fontsize=fs)        \n",
    "    \n",
    "    cbar_ax = fig.add_axes([0.91, 0.11, 0.01, 0.77])\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label(\"PET [mm/day]\", labelpad=10)\n",
    "    axs[0,0].text(-0.13, 0.55, 'pm_fao56', va='bottom', ha='center', fontsize=fs,\n",
    "            rotation='vertical', rotation_mode='anchor', transform=axs[0,0].transAxes)\n",
    "    axs[1,0].text(-0.13, 0.55, 'makkink', va='bottom', ha='center', fontsize=fs,\n",
    "                 rotation='vertical', rotation_mode='anchor', transform=axs[1,0].transAxes)\n",
    "    axs[2,0].text(-0.13, 0.55, 'hargreaves', va='bottom', ha='center', fontsize=fs,\n",
    "            rotation='vertical', rotation_mode='anchor', transform=axs[2,0].transAxes)\n",
    "        \n",
    "except ImportError:\n",
    "    fig, axs = plt.subplots(ncols=3, nrows=3, figsize=(16, 9), sharey=True, sharex=True)    \n",
    "    for date, i in zip([\"2018-6-6\", \"2018-6-7\", \"2018-6-8\"],[0,1,2]):\n",
    "        im1 = pm_fao56.sel(time=date).plot(ax=axs[0,i],vmax=vmax, vmin=vmin, add_colorbar=False, cmap=cmap)\n",
    "        im2 = makkink.sel(time=date).plot(ax=axs[1,i],vmax=vmax, vmin=vmin, add_colorbar=False, cmap=cmap)\n",
    "        im3 = hargreaves.sel(time=date).plot(ax=axs[2,i],vmax=vmax, vmin=vmin, add_colorbar=False, cmap=cmap)\n",
    "\n",
    "    for method, date, i in zip([\"pm_fao56\", \"makkink\", \"hargreaves\"], [\"2018-6-6\", \"2018-6-7\", \"2018-6-8\"],[0,1,2]):\n",
    "        for j in (0,1,2):        \n",
    "            axs[i, j].set_ylabel(\"\")\n",
    "            axs[i, j].set_xlabel(\"\")\n",
    "            axs[i, j].set_title(\"\")\n",
    "            axs[2,j].set_xlabel(\"Lon. [°E]\")\n",
    "        axs[i, 0].set_ylabel(method + \"\\n\\nLat. [°N]\")\n",
    "        axs[0,i].set_title(\"date=\"+date)\n",
    "    axs[0,0].set_xlabel(\"alalal\")\n",
    "    cbar_ax = fig.add_axes([0.91, 0.11, 0.01, 0.77])\n",
    "    cbar = fig.colorbar(im3, cax=cbar_ax)\n",
    "    cbar.set_label(\"PET [mm/day]\", labelpad=10)\n",
    "    plt.subplots_adjust(hspace=0.02, wspace=0.1)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.02, wspace=0.01);\n",
    "\n",
    "#fig.savefig(\"figure3.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84918f2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 5. Example 3: Calibration of PET models\n",
    "\n",
    "Data source: ZAMG - https://data.hub.zamg.ac.at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b91863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load station data\n",
    "data_16412 = pd.read_csv('data/example_1/klima_daily.csv', index_col=1, parse_dates=True)\n",
    "data_16412.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Glabalstrahlung J/cm2 to MJ/m2 by dividing to 100\n",
    "meteo = pd.DataFrame({\"time\":data_16412.index, \"tmean\":data_16412.t, \"tmax\":data_16412.tmax, \n",
    "                      \"tmin\":data_16412.tmin, \"rh\":data_16412.rel, \n",
    "                      \"wind\":data_16412.vv, \"rs\":data_16412.strahl/100})\n",
    "\n",
    "time, tmean, tmax, tmin, rh, wind, rs = [meteo[col] for col in meteo.columns]\n",
    "\n",
    "lat = 47.077778 * np.pi / 180  # Latitude of the meteorological station, converting from degrees to radians\n",
    "elevation = 367  # meters above sea-level\n",
    "\n",
    "# Estimate evaporation with all different methods and create a dataframe\n",
    "pet_df = pyet.calculate_all(tmean, wind, rs, elevation, lat, tmax=tmax,\n",
    "                            tmin=tmin, rh=rh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f6cd92-16c0-446f-9343-d26671613614",
   "metadata": {},
   "source": [
    "### 5.1 Calibrate alternative temperature models to Penman-Monteith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68610698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate alternative temperature models to Penman-Monteith\n",
    "methods = [\"oudin\", \"hargreaves\", \"mcguinness_bordne\", \"hamon\", \"blaney_criddle\"]\n",
    "\n",
    "# Define initial values for calibration for each method\n",
    "params = [[100, 5], [0.0135], [0.0147], [1], [-1.55, 0.96]]\n",
    "\n",
    "# Define input for each method\n",
    "input2 = ([tmean, lat], [tmean, tmax, tmin, lat], [tmean, lat],\n",
    "          [tmean, lat], [tmean, lat])\n",
    "\n",
    "# Define function to simulate the models and use required input\n",
    "def simulate(params, method, input1):   \n",
    "    input1_1 = input1.copy()\n",
    "    method = getattr(pyet, method)\n",
    "    for par in params:\n",
    "        input1_1.append(par)\n",
    "    return method(*input1_1)\n",
    "\n",
    "# Define function to estimate residuals    \n",
    "def residuals(params, info):\n",
    "    method, input1, obs = info\n",
    "    sim = simulate(params, method, input1)\n",
    "    return sim - obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aadada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate the models to Penman-Monteith\n",
    "obs = pet_df[\"FAO-56\"]\n",
    "sollutions2 = []\n",
    "for i in np.arange(0,len(methods)):\n",
    "    res_1 = least_squares(residuals, params[i], args=[[methods[i], input2[i], obs]])\n",
    "    sollutions2.append(res_1.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e8589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with PET estimated with default (params) and calibrated parameters(sollutions2)\n",
    "pet_df_def = pd.DataFrame()\n",
    "pet_df_cali = pd.DataFrame()\n",
    "for i in np.arange(0, len(methods)):\n",
    "    pet_df_def[methods[i]] = simulate(params[i], methods[i], input2[i])\n",
    "    pet_df_cali[methods[i]] = simulate(sollutions2[i], methods[i], input2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d156c21f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.2 Hindcasting PET for Graz, Austria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebebb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spartacus dataset\n",
    "spartacus = xr.open_dataset(\"data/example_10/spartacus-daily_19610101T0000_20211231T0000.nc\", \n",
    "                            engine=\"netcdf4\")\n",
    "spartacus_cali = spartacus.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794bad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new input\n",
    "tmean_spartacus = (spartacus[\"Tx\"] + spartacus[\"Tn\"]) / 2\n",
    "tmax_spartacus = spartacus[\"Tx\"]\n",
    "tmin_spartacus = spartacus[\"Tn\"]\n",
    "lat_spartacus = spartacus.lat * np.pi / 180  # from degrees to radians\n",
    "input_spartacus = ([tmean_spartacus, lat_spartacus], \n",
    "                   [tmean_spartacus, tmax_spartacus, tmin_spartacus, lat_spartacus], \n",
    "                   [tmean_spartacus, lat_spartacus],\n",
    "                   [tmean_spartacus, lat_spartacus], [tmean_spartacus, lat_spartacus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659c0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate PET and add it to the xarray.Dataset\n",
    "for i in np.arange(0,len(methods)):\n",
    "    spartacus[methods[i]] = simulate(params[i], methods[i], input_spartacus[i])\n",
    "    spartacus_cali[methods[i]] = simulate(sollutions2[i], methods[i], input_spartacus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8299db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with PET estimated with default (params) and calibrated (sollutions2) models\n",
    "df_def = spartacus.to_dataframe().reset_index(level=[1,1]).drop(columns=[\"y\", \"Tn\", \"Tx\", \"lambert_conformal_conic\", \"lon\", \"lat\"])\n",
    "df_cali = spartacus_cali.to_dataframe().reset_index(level=[1,1]).drop(columns=[\"y\", \"Tn\", \"Tx\", \"lambert_conformal_conic\", \"lon\", \"lat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c477f92-7188-48f1-a86a-6fc261a8c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_1(ax, x, y, label=\"treatment\", xlabel=\"obs\", ylabel=\"sim\",\n",
    "              best_fit=True, veg_ws=None):\n",
    "    compare = pd.DataFrame({\"x\": x, \"y\": y})\n",
    "    if veg_ws is not None:\n",
    "        compare[veg_ws == 0] = np.nan\n",
    "    compare = compare.dropna()\n",
    "    xy = np.vstack([compare[\"x\"].values,compare[\"y\"].values])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "    density = ax.scatter(compare[\"x\"], compare[\"y\"], marker=\"o\", s=2, c=z)#, fillstyle=\"none\")\n",
    "    ax.plot([-0.1, 10], [-0.1, 10], color=\"dodgerblue\", alpha=0.7,\n",
    "            linewidth=\"0.8\")\n",
    "    ax.axes.set_xticks(np.arange(0, 10 + 2, 2))\n",
    "    ax.axes.set_yticks(np.arange(0, 10 + 2, 2))\n",
    "    ax.set_xlim(-0.1, 10)\n",
    "    ax.set_ylim(-0.1, 10)\n",
    "    if best_fit:\n",
    "        p = np.polyfit(compare[\"x\"], compare[\"y\"], 1)\n",
    "        f = np.poly1d(p)\n",
    "\n",
    "        # Calculating new x's and y's\n",
    "        x_new = np.linspace(0, 10, y.size)\n",
    "        y_new = f(x_new)\n",
    "\n",
    "        # Plotting the best fit line with the equation as a legend in latex\n",
    "        ax.plot(x_new, y_new, \"r--\", linewidth=\"0.8\")\n",
    "    ax.text(0.02, 0.9, f\"{label}\", color=\"k\", zorder=10,\n",
    "            transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.04, \"$Bias$ = \" + str(\n",
    "        round(bias(np.asarray(compare[\"y\"]), np.asarray(compare[\"x\"])), 2)) +\n",
    "            \"\\n\" + \"$R^2$ = \" + str(\n",
    "        round(rsquared(np.asarray(compare[\"y\"]), np.asarray(compare[\"x\"])),\n",
    "              2)) +\n",
    "            \"\\n\" + \"KGE = \" + str(\n",
    "        round(kge(np.asarray(compare[\"y\"]), np.asarray(compare[\"x\"])), 2)),\n",
    "            color=\"k\", zorder=10, transform=ax.transAxes)\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a79765",
   "metadata": {},
   "outputs": [],
   "source": [
    "figw_1c = 8.5  # maximum width for 1 column\n",
    "figw_2c = 17.5  # maximum width for 2 columns\n",
    "\n",
    "fig, axs = plt.subplots(ncols=6, nrows=2, figsize=(figw_2c, 5), dpi=300)\n",
    "for i in np.arange(0, len(methods)):\n",
    "    density = scatter_1(axs[0,i], obs, simulate(params[i], methods[i], input2[i]), label=f\"{methods[i]} - default\")\n",
    "    density = scatter_1(axs[1,i], obs, simulate(sollutions2[i], methods[i], input2[i]), label=f\"{methods[i]} - calibrated\")\n",
    "    axs[0, i].set_xticklabels([])\n",
    "    axs[1, i].set_xlabel(r\"PET$_{sim}$ [mm/d]\")\n",
    "    axs[1, i].set_xticklabels((0,2,4,6,8,\"\"))\n",
    "for col in (1, 2, 3, 4):\n",
    "    axs[0, col].set_yticklabels([])\n",
    "    axs[1, col].set_yticklabels([])\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "for row in (0, 1):\n",
    "    axs[row, 0].set_ylabel(r\"PET$_{FAO-56}$ [mm/d]\")\n",
    "\n",
    "viridis = cm.get_cmap('viridis', len(df_def.columns))\n",
    "colors = [viridis(i) for i in range(0, len(df_def.columns))]\n",
    "df_def.resample(\"y\").sum().plot(ax=axs[0, 5], legend=False, color=colors)\n",
    "df_cali.resample(\"y\").sum().plot(ax=axs[1, 5], legend=False, color=colors)\n",
    "axs[0,5].axvline(pd.Timestamp(\"2000-1-1\"), color=\"k\", linestyle=\"--\", lw=1)\n",
    "axs[1,5].axvline(pd.Timestamp(\"2000-1-1\"), color=\"k\", linestyle=\"--\", lw=1)\n",
    "#pet_df_def.cumsum().plot(ax=axs[0, 5], legend=False)\n",
    "#obs.cumsum().plot(ax=axs[0,5], label=\"pm_fao56$ [mm/d]\", color=\"k\", linestyle=\"--\", )\n",
    "#obs.cumsum().plot(ax=axs[1,5], label=\"pm_fao56\", color=\"k\", linestyle=\"--\", )\n",
    "#pet_df_cali.cumsum().plot(ax=axs[1, 5], legend=False)\n",
    "for i in (0,1):\n",
    "    axs[i,5].yaxis.tick_right()\n",
    "    axs[i,5].yaxis.set_label_position(\"right\")\n",
    "    axs[i,5].set_xticks((pd.Timestamp(\"2016-1-1\"), pd.Timestamp(\"2018-1-1\"), pd.Timestamp(\"2020-1-1\")))\n",
    "    axs[i,5].set_ylim(600, 1200)\n",
    "    axs[i,5].set_ylabel(\"Cumulative PET [mm]\", fontsize=14)\n",
    "axs[0,5].set_xticklabels(\"\");\n",
    "axs[1,5].set_xticks([\"1960-1-1\", \"1980-1-1\", \"2000-1-1\", \"2021-1-1\"]);\n",
    "axs[1,5].set_xticklabels([\"1960\", \"1980\", \"2000\", \"2021\"]);\n",
    "axs[0,5].set_xlabel(\"\");\n",
    "plt.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "axs[1,5].set_yticklabels([\"\",800,1000,\"\"])\n",
    "axs[0,5].legend(loc=(-3.65,1.05), ncol=7, bbox_transform=axs[1,5].transAxes)\n",
    "clb = fig.colorbar(density, orientation=\"horizontal\", ax=axs[0, 0], cax = axs[0, 0].inset_axes([0.04, 1.2, 1, 0.05]))\n",
    "clb.ax.set_title(\"Number of points per pixel\");\n",
    "#fig.savefig(\"figure4.png\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46ea03",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 6. Example 4: Forecasting for Graz Austria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18d232",
   "metadata": {},
   "source": [
    "$$ PET_{CO_2} = f_{CO_2} PET $$\n",
    "\n",
    "Data source temperature: https://climate-impact-explorer.climateanalytics.org/impacts/\n",
    "\n",
    "Data source $CO_2$ levels: https://tntcat.iiasa.ac.at/RcpDb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85f2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load increase in temperature for each RCP scenario\n",
    "rcp_temp = pd.read_csv(\"data/example_10/tasAdjust_AUT_AT.ST_area_annual.csv\", \n",
    "                       skiprows=4, index_col=\"year\").loc[\"2020\":,:]\n",
    "rcp_temp = rcp_temp.loc[:, [\"RCP2.6 median\", \"RCP4.5 median\", \"RCP6.0 median\", \"RCP8.5 median\"]]\n",
    "rcp_temp.columns = [\"rcp_26\", \"rcp_45\", \"rcp_60\", \"rcp_85\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CO2 data for each RCP scenario\n",
    "rcp_co2 = pd.DataFrame()\n",
    "rcp_co2[\"rcp_26\"] = pd.read_csv(\"data/example_10/co2_conc/RCP3PD_MIDYR_CONC.DAT\", skiprows=38, \n",
    "                                delim_whitespace=True, index_col=\"YEARS\").loc[\"2020\":\"2100\", \"CO2\"]\n",
    "rcp_co2[\"rcp_45\"] = pd.read_csv(\"data/example_10/co2_conc/RCP45_MIDYR_CONC.DAT\", skiprows=38, \n",
    "                                delim_whitespace=True, index_col=\"YEARS\").loc[\"2020\":\"2100\", \"CO2\"]\n",
    "rcp_co2[\"rcp_60\"] = pd.read_csv(\"data/example_10/co2_conc/RCP6_MIDYR_CONC.DAT\", skiprows=38, \n",
    "                                delim_whitespace=True, index_col=\"YEARS\").loc[\"2020\":\"2100\", \"CO2\"]\n",
    "rcp_co2[\"rcp_85\"] = pd.read_csv(\"data/example_10/co2_conc/RCP85_MIDYR_CONC.DAT\", skiprows=38, \n",
    "                                delim_whitespace=True, index_col=\"YEARS\").loc[\"2020\":\"2100\", \"CO2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1bf22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RCP scenario 6.0\n",
    "co2_600 = 600\n",
    "pet_300 = pyet.pm(tmean, wind, rs=rs, elevation=elevation, lat=lat, \n",
    "                 tmax=tmax, tmin=tmin, rh=rh)\n",
    "pet_600 = pyet.pm(tmean, wind, rs=rs, elevation=elevation, lat=lat, \n",
    "                 tmax=tmax, tmin=tmin, rh=rh, co2=co2_600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f14c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sensitivity of PET to CO2\n",
    "def residuals_co2(S_CO2, PETco2, PETamb, co2):\n",
    "    fco2 = (1+S_CO2*(co2-300))\n",
    "    return PETco2 - PETamb * fco2\n",
    "\n",
    "res1 = least_squares(residuals_co2, [0.02], args=[pet_600, pet_300, 600])\n",
    "res1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input for each method\n",
    "inputamb = ([tmean, lat], [tmean, tmax, tmin, lat], [tmean, lat],\n",
    "         [tmean, lat], [tmean, lat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ef088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for input\n",
    "def input_rcp(tincrease):\n",
    "    return ([tmean+tincrease, lat], [tmean+tincrease, tmax+tincrease, tmin+tincrease, lat], [tmean+tincrease, lat],\n",
    "         [tmean+tincrease, lat], [tmean+tincrease, lat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PET for each year for each RCP scenario with 5-95 percentile\n",
    "dpet_rcp_et = pd.DataFrame(index=rcp_temp.index, columns=[\"rcp_26\", \"rcp_45\", \"rcp_60\", \"rcp_85\"])\n",
    "dpet_rcp_et_5th = pd.DataFrame(index=rcp_temp.index, columns=[\"rcp_26\", \"rcp_45\", \"rcp_60\", \"rcp_85\"])\n",
    "dpet_rcp_et_95th = pd.DataFrame(index=rcp_temp.index, columns=[\"rcp_26\", \"rcp_45\", \"rcp_60\", \"rcp_85\"])\n",
    "dpet_rcp_etco2 = pd.DataFrame(index=rcp_temp.index, columns=[\"rcp_26\", \"rcp_45\", \"rcp_60\", \"rcp_85\"])\n",
    "dpet_rcp_etco2_5th = pd.DataFrame(index=rcp_temp.index, columns=[\"rcp_26\", \"rcp_45\", \"rcp_60\", \"rcp_85\"])\n",
    "dpet_rcp_etco2_95th = pd.DataFrame(index=rcp_temp.index, columns=[\"rcp_26\", \"rcp_45\", \"rcp_60\", \"rcp_85\"])\n",
    "for year in rcp_temp.index:  \n",
    "    for rcp in [\"rcp_26\", \"rcp_45\", \"rcp_60\", \"rcp_85\"]:\n",
    "        df_rcp_et = pd.DataFrame()\n",
    "        df_rcp_etco2 = pd.DataFrame()\n",
    "        for i in np.arange(0, len(methods[:2])): # only for two methods to reduce processing for RTD to handle!!!!!!!!!!!!\n",
    "            input1 = input_rcp(rcp_temp.loc[year, rcp])\n",
    "            df_rcp_et[methods[i]] = simulate(sollutions2[i], methods[i], input1[i])\n",
    "            df_rcp_etco2[methods[i]] = simulate(sollutions2[i], methods[i], \n",
    "                                                input1[i]) * (1+res1.x*(rcp_co2.loc[year, rcp]-300))\n",
    "        dpet_rcp_et.loc[year, rcp] = df_rcp_et.resample(\"y\").mean().mean().mean()\n",
    "        dpet_rcp_et_5th.loc[year, rcp] = df_rcp_et.resample(\"y\").mean().mean().quantile(0.05)\n",
    "        dpet_rcp_et_95th.loc[year, rcp] = df_rcp_et.resample(\"y\").mean().mean().quantile(0.95)\n",
    "        dpet_rcp_etco2.loc[year, rcp] = df_rcp_etco2.resample(\"y\").mean().mean().mean()\n",
    "        dpet_rcp_etco2_5th.loc[year, rcp] = df_rcp_etco2.resample(\"y\").mean().mean().quantile(0.05)\n",
    "        dpet_rcp_etco2_95th.loc[year, rcp] = df_rcp_etco2.resample(\"y\").mean().mean().quantile(0.95)\n",
    "        # Call gc.collect() after processing each RCP scenario for a year\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d45437",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpet_rcp_et = dpet_rcp_et.apply(pd.to_numeric)\n",
    "dpet_rcp_et_5th = dpet_rcp_et_5th.apply(pd.to_numeric)\n",
    "dpet_rcp_et_95th = dpet_rcp_et_95th.apply(pd.to_numeric)\n",
    "dpet_rcp_etco2 = dpet_rcp_etco2.apply(pd.to_numeric)\n",
    "dpet_rcp_etco2_5th = dpet_rcp_etco2_5th.apply(pd.to_numeric)\n",
    "dpet_rcp_etco2_95th = dpet_rcp_etco2_95th.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c97280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(6, 5), constrained_layout=True, sharex=True)\n",
    "axs = axs.flatten()\n",
    "viridis = cm.get_cmap('viridis', len(rcp_temp.columns))\n",
    "colors = [viridis(i) for i in range(0, len(rcp_temp.columns))]\n",
    "\n",
    "for col, rcp, name in zip(colors, rcp_temp.columns, [\"RCP 2.6\", \"RCP 4.5\", \"RCP 6.0\", \"RCP 8.5\"]):\n",
    "    axs[2].plot(dpet_rcp_et.loc[:, rcp]-dpet_rcp_et.loc[2020, rcp], c=col);\n",
    "    axs[2].fill_between(dpet_rcp_et.index, dpet_rcp_et_5th[rcp]-dpet_rcp_et.loc[2020, rcp], \n",
    "                        dpet_rcp_et_95th[rcp]-dpet_rcp_et.loc[2020, rcp], color=col, alpha=0.2)\n",
    "    axs[3].fill_between(dpet_rcp_et.index, dpet_rcp_etco2_5th[rcp]-dpet_rcp_etco2.loc[2020, rcp], \n",
    "                        dpet_rcp_etco2_95th[rcp]-dpet_rcp_etco2.loc[2020, rcp], color=col, alpha=0.2)\n",
    "    axs[3].plot(dpet_rcp_etco2.loc[:, rcp]-dpet_rcp_etco2.loc[2020, rcp], c=col);\n",
    "    axs[1].plot(rcp_co2[rcp], c=col)\n",
    "    axs[0].plot(rcp_temp[rcp], c=col, label=name)\n",
    "\n",
    "axs[0].set_ylabel(r\"$\\Delta$T [°C]\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_ylabel(\"$CO_2$ [ppm]]\")\n",
    "\n",
    "axs[2].set_ylim(0, 0.79)\n",
    "axs[2].set_ylabel(\"$\\Delta$PET [mm/day]\")\n",
    "\n",
    "axs[3].set_ylim(0, 0.79)\n",
    "#axs[3].set_xlim(\"2020\", \"2100\")\n",
    "axs[2].set_ylabel(\"$\\Delta$PET [mm/day]\")\n",
    "\n",
    "axs[2].text(2025, 0.7, \"T+\", fontsize=14)\n",
    "axs[3].text(2025, 0.7, \"T + $CO_2$+\", fontsize=14)\n",
    "\n",
    "for i, letter in enumerate([\"a\", \"b\", \"c\", \"d\"]):\n",
    "    axs[i].text(0.85, 0.9, \"({})\".format(letter), transform=axs[i].transAxes, fontsize=12)\n",
    "    axs[i].tick_params(axis='both', which='major', labelsize=13);\n",
    "\n",
    "#fig.savefig(\"figure5.png\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb2272",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7. Code example in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d21bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import needed Python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 2. Reading meteorological data\n",
    "meteo = pd.read_csv(\"data/example_10/10_example_meteo.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# 3. Determining the necessary input data\n",
    "tmean, tmax, tmin, rh, rs, wind, pet_knmi = (meteo[col] for col in meteo.columns)\n",
    "lat = 0.91  # define latitude [radians]\n",
    "elev = 4  # define elevation [meters above sea-level]\n",
    "\n",
    "# 4. Estimate PET (all methods) and save the results in a Pandas.DataFrame\n",
    "pet_df = pyet.calculate_all(tmean, wind, rs, elev, lat, tmax, tmin, rh)\n",
    "                           \n",
    "# (4. Estimate potential evaporation - Example with one method)\n",
    "pyet_makkink = pyet.makkink(tmean, rs, elevation=elev)\n",
    "\n",
    "# 5. Plot PET \n",
    "pet_df.plot()  # daily PET [mm/day]\n",
    "pet_df.boxplot()  # boxplot PET[mm/day]\n",
    "pet_df.cumsum().plot()  # cummulative PET [mm]\n",
    "plt.scatter(pyet_makkink, pet_knmi)  # plot Makkink pyet vs KNMI;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c2479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Reading meteorological data\n",
    "meteo = pd.read_csv(\"data//example_10//10_example_meteo.csv\", index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b5ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Determining the necessary input data\n",
    "tmean, tmax, tmin, rh, rs, wind, pet_knmi = (meteo[col] for col in meteo.columns)\n",
    "lat = 0.91  # define latitude [radians]\n",
    "elevation = 4  # define elevation [meters above sea-level]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bae9c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now that we have defined the input data, we can estimate potential evaporation with different estimation methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f684ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Estimate potential evaporation (with all available methods) and save the results in a Pandas.DataFrame\n",
    "pet_df  = pyet.calculate_all(tmean, wind, rs, elevation, lat, tmax, tmin, rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8652d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Estimate PE and save the results in a xarray.DataArray\n",
    "pe_pm_fao56 = pyet.pm_fao56(tmean, wind, rs=rs, elevation=elevation, \n",
    "                            lat=lat, tmax=tmax, tmin=tmin, rh=rh)\n",
    "pe_makkink = pyet.makkink(tmean, rs, elevation=elevation)\n",
    "pe_pt = pyet.priestley_taylor(tmean, rs=rs, elevation=elevation, \n",
    "                              lat=lat, tmax=tmax, tmin=tmin, rh=rh)\n",
    "pe_hamon = pyet.hamon(tmean, lat=lat) \n",
    "pe_blaney_criddle = pyet.blaney_criddle(tmean, lat)\n",
    "pe_hargreaves = pyet.hargreaves(tmean, tmax, tmin, lat=lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea54c53-23d9-446a-ba49-b954d10f15f6",
   "metadata": {},
   "source": [
    "# 8. Computation time\n",
    "\n",
    "Comparison of the computational time and time series length  and xarray grid size for different *pyet* PET modelds. The plot shows (a) the mean computational time and 95 % confidence interval for each model against the time series length, represented by a line and corresponding colored region, respectively. (b) the mean computational time and 95 % confidence interval for each model against the grid size of the xarray with 30 years time series length, represented by a line and corresponding colored region, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af6625-88d4-448c-9611-0ca14559ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading meteorological data\n",
    "df_10_days = pd.read_csv(\"data//example_10//10_example_meteo.csv\", index_col=0, parse_dates=True).iloc[:10, :-1]\n",
    "\n",
    "# Determining the necessary input data\n",
    "lat = 0.91  # define latitude [radians]\n",
    "elevation = 4  # define elevation [meters above sea-level]\n",
    "\n",
    "# Function to replicate DataFrame to N days using the same values, maintaining a continuous date index\n",
    "def extend_data(df, n_days):\n",
    "    n_replications = n_days // len(df)  # Calculate how many times to replicate the DataFrame\n",
    "    extended_data = np.tile(df.values, (n_replications, 1))  # Replicate the data values\n",
    "    start_date = df.index[0]\n",
    "    end_date = start_date + pd.Timedelta(days=n_days - 1)\n",
    "    new_index = pd.date_range(start=start_date, end=end_date, freq='D')  # New continuous date index\n",
    "    extended_df = pd.DataFrame(extended_data[:len(new_index)], index=new_index, columns=df.columns)  # DataFrame with new index\n",
    "    return extended_df\n",
    "\n",
    "# Extending the DataFrame to 100, 1000, and 10000 days...\n",
    "dfs_time = {}\n",
    "dfs_time[\"10\"] = df_10_days\n",
    "dfs_time[\"100\"] = extend_data(df_10_days, 100)\n",
    "dfs_time[\"1000\"] = extend_data(df_10_days, 1000)\n",
    "dfs_time[\"10000\"] = extend_data(df_10_days, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594a1268-5fb9-41c1-b2d9-93d2ff7a9f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "# Compute times\n",
    "def compute_pet_and_time(method, length):\n",
    "    # Determining the necessary input data\n",
    "    tmean, tmax, tmin, rh, rs, wind = (dfs_time[length][col] for col in df_10_days.columns)\n",
    "    start_time = time.time()\n",
    "    if method == \"pm\":\n",
    "        pet = pyet.pm(tmean, wind, rs=rs, tmax=tmax, tmin=tmin, rh=rh, lat=lat, elevation=elevation)\n",
    "    elif method == \"oudin\":\n",
    "        pet = pyet.oudin(tmean, lat)\n",
    "    elif method == \"hamon\":\n",
    "        pet = pyet.hamon(tmean, lat)\n",
    "    elif method == \"hargreaves\":\n",
    "        pet = pyet.hargreaves(tmean, tmax, tmin, lat)\n",
    "    elif method == \"priestley_taylor\":\n",
    "        pet = pyet.priestley_taylor(tmean, rs=rs, tmax=tmax, tmin=tmin, lat=lat, elevation=elevation, rh=rh)\n",
    "    elif method == \"romanenko\":\n",
    "        pet = pyet.romanenko(tmean, rh)\n",
    "    elif method == \"makkink\":\n",
    "        pet = pyet.makkink(tmean, rs, elevation=elevation)\n",
    "    elif method == \"jensen_haise\":\n",
    "        pet = pyet.jensen_haise(tmean, rs=rs, lat=lat)\n",
    "    elif method == \"turc\":\n",
    "        pet = pyet.turc(tmean, rs, rh)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method\")\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645bb32-b525-49ac-b677-b8d43348798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary to store the computed times\n",
    "mean_times = {\"pm\": [], \"oudin\": [], \"hamon\": [], \"hargreaves\": [], \"priestley_taylor\": [], \n",
    "         \"romanenko\": [], \"makkink\": [], \"jensen_haise\": [], \"turc\": []}\n",
    "times_25= {\"pm\": [], \"oudin\": [], \"hamon\": [], \"hargreaves\": [], \"priestley_taylor\": [], \n",
    "         \"romanenko\": [], \"makkink\": [], \"jensen_haise\": [], \"turc\": []}\n",
    "times_975 = {\"pm\": [], \"oudin\": [], \"hamon\": [], \"hargreaves\": [], \"priestley_taylor\": [], \n",
    "         \"romanenko\": [], \"makkink\": [], \"jensen_haise\": [], \"turc\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a5c5c-3401-4262-86cf-3af8eb5d0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over different time series lengths and methods\n",
    "lengths = [10, 100, 1000, 10000] \n",
    "for length in lengths:\n",
    "    for method in [\"pm\", \"oudin\", \"hamon\", \"hargreaves\", \"priestley_taylor\", \"romanenko\", \"makkink\", \"jensen_haise\", \"turc\"]:\n",
    "        times_100 = []\n",
    "        for i in range(100):\n",
    "            times_100.append(compute_pet_and_time(method, str(length)))\n",
    "        mean_times[method].append(np.mean(times_100))\n",
    "        #times_25[method].append(np.quantile(times_100, 0.025))\n",
    "        #times_975[method].append(np.quantile(times_100, 0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55f0f56-4185-4268-9913-7f8f0935b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load xarray dataset\n",
    "wind = xr.open_dataset(\"data/example_10/fg_ens_mean_0.25deg_reg_2018_v25.0e.nc\", \n",
    "                       engine=\"netcdf4\")[\"fg\"]\n",
    "tmax = xr.open_dataset(\"data/example_10/tx_ens_mean_0.25deg_reg_2018_v25.0e.nc\", \n",
    "                       engine=\"netcdf4\").sel(longitude=slice(wind.longitude.min(), wind.longitude.max()), \n",
    "                                             latitude=slice(wind.latitude.min(), wind.latitude.max()))[\"tx\"]\n",
    "tmin = xr.open_dataset(\"data/example_10/tn_ens_mean_0.25deg_reg_2018_v25.0e.nc\", \n",
    "                       engine=\"netcdf4\").sel(longitude=slice(wind.longitude.min(), wind.longitude.max()), \n",
    "                                             latitude=slice(wind.latitude.min(), wind.latitude.max()))[\"tn\"]\n",
    "tmean = xr.open_dataset(\"data/example_10/tg_ens_mean_0.25deg_reg_2018_v25.0e.nc\", \n",
    "                        engine=\"netcdf4\").sel(longitude=slice(wind.longitude.min(), wind.longitude.max()), \n",
    "                                              latitude=slice(wind.latitude.min(), wind.latitude.max()))[\"tg\"]\n",
    "rs = xr.open_dataset(\"data/example_10/qq_ens_mean_0.25deg_reg_2018_v25.0e.nc\", \n",
    "                     engine=\"netcdf4\").sel(lon=slice(wind.longitude.min(), wind.longitude.max()), \n",
    "                                           lat=slice(wind.latitude.min(), wind.latitude.max()))\n",
    "rs = rs.rename_dims({\"lon\":\"longitude\", \n",
    "                     \"lat\":\"latitude\"}).rename({\"lon\":\"longitude\", \n",
    "                                                \"lat\":\"latitude\"}).sel(ensemble=10)[\"qq\"] * 86400 / 1000000  # concert to [MJ/m2day]\n",
    "rh = xr.open_dataset(\"data/example_10/hu_ens_mean_0.25deg_reg_2018_v25.0e.nc\", \n",
    "                     engine=\"netcdf4\").sel(lon=slice(wind.longitude.min(), wind.longitude.max()), \n",
    "                                           lat=slice(wind.latitude.min(), wind.latitude.max()))\n",
    "rh = rh.rename_dims({\"lon\":\"longitude\", \"lat\":\"latitude\"}).rename({\"lon\":\"longitude\", \"lat\":\"latitude\"})[\"hu\"]\n",
    "wind = wind.sel(longitude=slice(rh.longitude.min(), rh.longitude.max()), latitude=slice(rh.latitude.min(), rh.latitude.max()))\n",
    "elevation =  xr.open_dataset(\"data/example_10/elev_ens_0.25deg_reg_v25.0e.nc\", \n",
    "                     engine=\"netcdf4\").sel(longitude=slice(wind.longitude.min(), wind.longitude.max()), \n",
    "                                           latitude=slice(wind.latitude.min(), wind.latitude.max()))[\"elevation\"].fillna(0)\n",
    "lat = tmean.latitude * np.pi / 180\n",
    "lat = lat.expand_dims(dim={\"longitude\":tmean.longitude}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889660f3-3569-4af4-a83c-ecd887732b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into a single dataset\n",
    "combined_ds = xr.Dataset({\"wind\": wind,\"tmax\": tmax, \"tmin\": tmin, \"tmean\":tmean,\n",
    "                          'rs': rs, 'rh': rh,'elevation': elevation, \"lat\":lat}).isel(latitude=slice(50, 60), longitude=slice(100, 110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c9fcb2-8a33-4a32-8561-756b403ef671",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_time = pd.date_range('2018-06-06', '2019-06-06')\n",
    "meteo_100 = combined_ds.reindex(time=new_time, method='ffill').rio.write_crs(\"EPSG:4326\")\n",
    "meteo_10 = meteo_100.isel(latitude=slice(0, 2), longitude=slice(0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e2ce6-c915-4bb5-a780-818724388689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print resolution\n",
    "print(abs(meteo_100.latitude.diff(\"latitude\").mean().values))\n",
    "print(abs(meteo_100.longitude.diff(\"longitude\").mean().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee868a38-32bc-4145-8f3d-3ea2046f4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create xarray.datarray with 100x100, 1000x1000\n",
    "meteo_10000 = meteo_100.rio.reproject(dst_crs=meteo_100.rio.crs, resolution=0.025).rename({'x': 'longitude', 'y': 'latitude'})\n",
    "meteo_1000 = meteo_10000.isel(latitude=slice(0, 20), longitude=slice(0, 50))\n",
    "meteo_1000000 = meteo_100.rio.reproject(dst_crs=meteo_100.rio.crs, resolution=0.0025).rename({'x': 'longitude', 'y': 'latitude'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9bb5b-d449-49a3-b540-d36d2033d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_100000 = meteo_1000000.isel(latitude=slice(0, 200), longitude=slice(0, 500))\n",
    "meteo_10000 = meteo_1000000.isel(latitude=slice(0, 20), longitude=slice(0, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac09e2b-0eb3-4a4e-9b58-c8d02fea2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "meteo_xr_dic = {\"10\":meteo_10, \"100\":meteo_100, \"1000\":meteo_1000, \"10000\":meteo_10000, \"100000\":meteo_100000, \"1000000\":meteo_1000000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e362d-59bb-4310-acd9-9c6f6a502078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute times\n",
    "def compute_pet_and_time_xr(method, length):\n",
    "    # Determining the necessary input data\n",
    "    wind, tmax, tmin, tmean, rs, rh, elevation, lat = (meteo_xr_dic[str(length)][col] for col in meteo_10.data_vars)\n",
    "    start_time = time.time()\n",
    "    if method == \"pm\":\n",
    "        #print(rh.min(), length)\n",
    "        pet = pyet.pm(tmean, wind, rs=rs, tmax=tmax, tmin=tmin, rh=rh, lat=lat, elevation=elevation)\n",
    "    elif method == \"oudin\":\n",
    "        pet = pyet.oudin(tmean, lat)\n",
    "    elif method == \"hamon\":\n",
    "        pet = pyet.hamon(tmean, lat)\n",
    "    elif method == \"hargreaves\":\n",
    "        pet = pyet.hargreaves(tmean, tmax, tmin, lat)\n",
    "    elif method == \"priestley_taylor\":\n",
    "        pet = pyet.priestley_taylor(tmean, rs=rs, tmax=tmax, tmin=tmin, lat=lat, elevation=elevation, rh=rh)\n",
    "    elif method == \"romanenko\":\n",
    "        pet = pyet.romanenko(tmean, rh)\n",
    "    elif method == \"makkink\":\n",
    "        pet = pyet.makkink(tmean, rs, elevation=elevation)\n",
    "    elif method == \"jensen_haise\":\n",
    "        pet = pyet.jensen_haise(tmean, rs=rs, lat=lat)\n",
    "    elif method == \"turc\":\n",
    "        pet = pyet.turc(tmean, rs, rh)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method\")\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291952b3-1afb-4982-b53d-590ac9337cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary to store the computed times\n",
    "mean_times_xr = {\"pm\": [], \"oudin\": [], \"hamon\": [], \"hargreaves\": [], \"priestley_taylor\": [], \n",
    "         \"romanenko\": [], \"makkink\": [], \"jensen_haise\": [], \"turc\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835bd1f9-0173-48f9-9b06-6161e84e652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over different time series lengths and methods\n",
    "lengths = [10, 100, 1000, 10000, 100000] \n",
    "for length in lengths:\n",
    "    for method in [\"pm\", \"oudin\", \"hamon\", \"hargreaves\", \"priestley_taylor\", \"romanenko\", \"makkink\", \"jensen_haise\", \"turc\"]:\n",
    "        times_100 = []\n",
    "        for i in range(10):\n",
    "            times_100.append(compute_pet_and_time_xr(method, str(length)))\n",
    "        mean_times_xr[method].append(np.mean(times_100))\n",
    "        #times_25[method].append(np.quantile(times_100, 0.025))\n",
    "        #times_975[method].append(np.quantile(times_100, 0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6d66ea-3a6d-445c-aab0-075bf31c0ea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot figure\n",
    "cmap_colrs = cm.get_cmap('Paired', len(mean_times.keys()))\n",
    "colors = [cmap_colrs(i) for i in range(0, len(mean_times.keys()))]\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(6,5), layout=\"constrained\")\n",
    "for method, color in zip(mean_times.keys(), colors):\n",
    "    axs[0].plot(mean_times[method], label=method, color=color)\n",
    "    #axs[0].fill_between(np.arange(0, len(lengths)), times_25[method], times_975[method], alpha=0.1)\n",
    "for method, color in zip(mean_times_xr.keys(), colors):\n",
    "    axs[1].plot(mean_times_xr[method], label=method, color=color)\n",
    "\n",
    "axs[0].set_xlabel(\"Time series length [days]\", size=12)\n",
    "for i in (0,1):\n",
    "    axs[i].set_ylabel(\"\")\n",
    "    axs[i].set_yscale(\"log\")\n",
    "    \n",
    "axs[0].set_xticks(np.arange(0, 4))\n",
    "axs[0].set_xticklabels([\"10$^1$\", \"10$^2$\", \"10$^3$\", \"10$^4$\"]);\n",
    "axs[0].set_xlim(-0.1, 3.1)\n",
    "\n",
    "axs[1].set_xticks(np.arange(0, 5))\n",
    "axs[1].set_xlim(-0.1, 4.1)\n",
    "axs[1].set_xticklabels([\"10$^1$\", \"10$^2$\", \"10$^3$\", \"10$^4$\", \"10$^5$\"]);\n",
    "\n",
    "fig.text(-0.04, 0.5, 'Computation time [s]', va='center', rotation='vertical', fontsize=14)\n",
    "axs[1].set_xlabel(\"Cell number [n]\", size=12)\n",
    "\n",
    "axs[0].legend(bbox_to_anchor=(0.5, 1.55), fontsize=11, ncol=3, loc=\"upper center\");\n",
    "plt.subplots_adjust(left=0.15, top=0.85);\n",
    "axs[0].text(0.02, 0.87, \"(a)\", fontsize=13, transform=axs[0].transAxes)\n",
    "axs[1].text(0.02, 0.87, \"(b)\", fontsize=13, transform=axs[1].transAxes)\n",
    "fig.savefig(\"figure6.png\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9318e-61ca-4034-b4f8-7b030b860576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d43d1f5e-0bbc-43f9-ac94-6f952278245e",
   "metadata": {},
   "source": [
    "## Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac81b2-c7f8-4670-b8a2-2a4f64368903",
   "metadata": {},
   "source": [
    "We acknowledge the financial support by the University of Graz and the funding of the Earth System Sciences research program of the the Austrian Academy of Sciences (ÖAW project ClimGrassHydro). We acknowledge the ZAMG dataset (https://data.hub.zamg.ac.at), KNMI dataset (https://www.knmi.nl/home), and the E-OBS dataset from the EU-FP6 project UERRA (http://www.uerra.eu) and the Copernicus Climate Change Service, and the data providers in the ECA\\&D project (https://www.ecad.eu). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69f71ff-fa2d-449a-9321-944acd4248b4",
   "metadata": {},
   "source": [
    "## Literature\n",
    "\n",
    "Abtew, W. (1996). Evapotranspiration measurements and modeling for three wetland systems in South Florida 1. JAWRA Journal of the American Water Resources Association, 32, 465-473. Publisher: Wiley Online Library.\n",
    "\n",
    "Allen, R.G., Pereira, L.S., Raes, D., Smith, M., & others. (1998). Crop evapotranspiration-Guidelines for computing crop water requirements-FAO Irrigation and drainage paper 56. Rome: Fao, 300, D05109.\n",
    "\n",
    "Ansorge, L., & Beran, A. (2019). Performance of simple temperature-based evaporation methods compared with a time series of pan evaporation measures from a standard 20 m2 tank. Journal of Water and Land Development, 41, 1-11. https://doi.org/10.2478/jwld-2019-0021.\n",
    "\n",
    "Guo, D., Westra, S., & Maier, H. R. (2016). An R package for modelling actual, potential and reference evapotranspiration. Environmental Modelling & Software, 78, 216-224.\n",
    "\n",
    "Hamon, W.R. (1963). Estimating potential evapotranspiration. Transactions of the American Society of Civil Engineers, 128, 324-338. Publisher: American Society of Civil Engineers.\n",
    "\n",
    "Hargreaves, G.H., & Samani, Z.A. (1982). Estimating potential evapotranspiration. Journal of the irrigation and Drainage Division, 108, 225-230. Publisher: American Society of Civil Engineers. https://doi.org/10.1061/(ASCE)0733-9437(1983)109:3(341).\n",
    "\n",
    "Haude, W. (1955). Determination of evapotranspiration by an approach as simple as possible. Mitt Dt Wetterdienst, 2.\n",
    "\n",
    "Jensen, M.E., & Allen, R.G. (2016). Evaporation, Evapotranspiration, and Irrigation Water Requirements (2nd ed.). American Society of Civil Engineers. _eprint: https://ascelibrary.org/doi/pdf/10.1061/, https://doi.org/10.1061/9780784414057.\n",
    "\n",
    "Jensen, M.E., Burman, R.D., Allen, R.G., & others. (1990). Evapotranspiration and irrigation water requirements. ASCE, New York.\n",
    "\n",
    "Jensen, M.E., & Haise, H.R. (1963). Estimating evapotranspiration from solar radiation. Journal of the Irrigation and Drainage Division, 89, 15-41. Publisher: American Society of Civil Engineers. https://doi.org/10.1061/JRCEA4.0000287.\n",
    "\n",
    "Linacre, E.T. (1977). A simple formula for estimating evaporation rates in various climates, using temperature data alone. Agricultural Meteorology, 18, 409-424. https://doi.org/https://doi.org/10.1016/0002-1571(77)90007-3.\n",
    "\n",
    "Makkink, G.F. (1957). Testing the Penman formula by means of lysimeters. Journal of the Institution of Water Engineerrs, 11, 277-288.\n",
    "\n",
    "McGuinness, J., & Bordne, E. (1972). A comparison of lysimeter derived potential evapotranspiration with computed values. Tech. Bull. Agric. Res. Serv., US Dep. of Agric., Washington, DC. https://doi.org/10.22004/ag.econ.171893.\n",
    "\n",
    "McMahon, T.A., Peel, M.C., Lowe, L., Srikanthan, R., & McVicar, T.R. (2013). Estimating actual, potential, reference crop and pan evaporation using standard meteorological data: a pragmatic synthesis. Hydrology and Earth System Sciences, 17, 1331-1363. https://doi.org/10.5194/hess-17-1331-2013.\n",
    "\n",
    "Monteith, J.L. (1965). Evaporation and environment. In Proceedings of the Symposia of the society for experimental biology. Cambridge University Press (CUP) Cambridge, Vol. 19, pp. 205-234.\n",
    "\n",
    "Oudin, L., Michel, C., & Anctil, F. (2005). Which potential evapotranspiration input for a lumped rainfall-runoff model? Journal of Hydrology, 303, 275-289. https://doi.org/10.1016/j.jhydrol.2004.08.025.\n",
    "\n",
    "Penman, H.L. (1948). Natural evaporation from open water, bare soil and grass. Proceedings of the Royal Society of London. Series A. Mathematical and Physical Sciences, 193, 120-145. Publisher: The Royal Society London.\n",
    "\n",
    "Priestley, C.H.B., & Taylor, R.J. (1972). On the assessment of surface heat flux and evaporation using large-scale parameters. Monthly weather review, 100, 81-92.\n",
    "\n",
    "Romanenko, V. (1961). Computation of the autumn soil moisture using a universal relationship for a large area. Proc. of Ukrainian Hydrometeorological Research Institute, 3, 12-25.\n",
    "\n",
    "Schiff, H. (1975). Berechnung der potentiellen Verdunstung und deren Vergleich mit aktuellen Verdunstungswerten von Lysimetern. Archiv für Meteorologie, Geophysik und Bioklimatologie, Serie B, 23, 331-342. Publisher: Springer. https://doi.org/https://doi.org/10.1007/BF02242689.\n",
    "\n",
    "Schrödter, H. (1985). Hinweise Für den Einsatz Anwendungsorientierter Bestimmungsverfahren. Berlin, Heidelberg: Springer Berlin Heidelberg. Publication Title: Verdunstung: Anwendungsorientierte Meßverfahren und Bestimmungsmethoden. https://doi.org/10.1007/978-3-642-70434-5_8.\n",
    "\n",
    "Xu, C.Y., & Singh, V.P. (2001). Evaluation and generalization of temperature-based methods for calculating evaporation. Hydrological Processes, 15, 305-319. https://doi.org/https://doi.org/10.1002/hyp.119.\n",
    "\n",
    "Thom, A., & Oliver, H. (1977). On Penman's equation for estimating regional evaporation. Quarterly Journal of the Royal Meteorological Society, 103, 345-357. Publisher: Wiley Online Library.\n",
    "\n",
    "Turc, L. (1961). Estimation of irrigation water requirements, potential evapotranspiration: a simple climatic formula evolved up to date. Ann. Agron, 12, 13-49.\n",
    "\n",
    "Walter, I.A., Allen, R.G., Elliott, R., Jensen, M., Itenfisu, D., Mecham, B., Howell, T., Snyder, R., Brown, P., Echings, S., et al. (2000). ASCE's standardized reference evapotranspiration equation. In Watershed management and operations management, pp. 1-11.\n",
    "\n",
    "Wright, J.L. (1982). New evapotranspiration crop coefficients. Proceedings of the American Society of Civil Engineers, Journal of the Irrigation and Drainage Division, 108, 57-74."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
